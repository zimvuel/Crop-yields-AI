{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Concatenate, Embedding, Flatten, Bidirectional, BatchNormalization, Activation, Multiply, Permute, RepeatVector, Lambda, GlobalAveragePooling1D\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import zipfile\n",
        "\n",
        "# ==========================================\n",
        "# 0. SETUP & UNZIP\n",
        "# ==========================================\n",
        "zip_filename = \"wow.zip\"\n",
        "if os.path.exists(zip_filename):\n",
        "    print(f\"Found {zip_filename}. Extracting...\")\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    print(\"✅ Extraction complete.\")\n",
        "else:\n",
        "    print(f\"⚠️ {zip_filename} not found. Assuming files are already present.\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIG & PATHS\n",
        "# ==========================================\n",
        "BASE_DIR = \".\"\n",
        "PATHS = {\n",
        "    \"climate\": os.path.join(BASE_DIR, \"iklim\", \"aa-combined.csv\"),\n",
        "    \"soil_moisture\": os.path.join(BASE_DIR, \"tanah\", \"soilmoisture.csv\"),\n",
        "    \"soil_static\": os.path.join(BASE_DIR, \"tanah\", \"soilstatic.csv\"),\n",
        "    \"harvest\": os.path.join(BASE_DIR, \"tanaman\", \"waktupanen.csv\"),\n",
        "    \"target\": os.path.join(BASE_DIR, \"tanaman\", \"biofarmaka.csv\"),\n",
        "    \"output\": os.path.join(BASE_DIR, \"Biofarmaka_Prediction_2025.csv\"),\n",
        "    \"plot_luas\": os.path.join(BASE_DIR, \"eval_luas_panen.png\"),\n",
        "    \"plot_prod\": os.path.join(BASE_DIR, \"eval_produksi.png\")\n",
        "}\n",
        "\n",
        "TRAIN_START = \"2023-11-01\"\n",
        "TRAIN_END = \"2024-12-31\"\n",
        "PREDICT_START = \"2025-01-01\"\n",
        "PREDICT_END = \"2025-10-31\"\n",
        "\n",
        "# HYPERTUNING: Increased Lookback Window to 90 days (Quarterly)\n",
        "# This captures a fuller crop cycle context\n",
        "LOOKBACK_WINDOW = 90\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATA LOADING & CLEANING\n",
        "# ==========================================\n",
        "def clean_province(prov):\n",
        "    if pd.isna(prov): return \"UNKNOWN\"\n",
        "    return str(prov).strip().upper()\n",
        "\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "for key in [\"climate\", \"soil_moisture\", \"soil_static\", \"harvest\", \"target\"]:\n",
        "    if not os.path.exists(PATHS[key]):\n",
        "        print(f\"❌ Warning: {key} file not found at {PATHS[key]}\")\n",
        "\n",
        "# Load climate\n",
        "df_climate = pd.read_csv(PATHS[\"climate\"])\n",
        "df_climate['TANGGAL'] = pd.to_datetime(df_climate['TANGGAL'], dayfirst=True, errors='coerce')\n",
        "df_climate = df_climate.dropna(subset=['TANGGAL'])\n",
        "df_climate['Provinsi'] = df_climate['Provinsi'].apply(clean_province)\n",
        "df_climate = df_climate.groupby(['TANGGAL', 'Provinsi']).mean(numeric_only=True).reset_index()\n",
        "\n",
        "# Load soil moisture\n",
        "df_moisture = pd.read_csv(PATHS[\"soil_moisture\"])\n",
        "df_moisture['Date'] = pd.to_datetime(df_moisture['Date'], errors='coerce')\n",
        "df_moisture['Provinsi'] = df_moisture['Provinsi'].apply(clean_province)\n",
        "df_moisture.rename(columns={'Date': 'TANGGAL', 'Soil_Moisture_%': 'Soil_Moisture'}, inplace=True)\n",
        "\n",
        "# Load soil static\n",
        "df_soil_static = pd.read_csv(PATHS[\"soil_static\"])\n",
        "df_soil_static['Provinsi'] = df_soil_static['Provinsi'].apply(clean_province)\n",
        "\n",
        "# Load harvest info\n",
        "df_harvest = pd.read_csv(PATHS[\"harvest\"])\n",
        "df_harvest['Avg_Harvest_Days'] = (df_harvest['Waktu Panen Minimum (Hari)'] + df_harvest['Waktu Panen Maksimum (Hari)']) / 2\n",
        "df_harvest = df_harvest[['Jenis Tanaman', 'Avg_Harvest_Days']]\n",
        "\n",
        "# Load target\n",
        "df_target = pd.read_csv(PATHS[\"target\"])\n",
        "df_target['Date'] = pd.to_datetime(df_target['Date'], errors='coerce')\n",
        "df_target['Provinsi'] = df_target['Provinsi'].apply(clean_province)\n",
        "df_target.rename(columns={'Date': 'TANGGAL'}, inplace=True)\n",
        "\n",
        "# ==========================================\n",
        "# 3. MERGE & FEATURES\n",
        "# ==========================================\n",
        "print(\"Merging data...\")\n",
        "\n",
        "all_dates = pd.date_range(start=TRAIN_START, end=PREDICT_END, freq='D')\n",
        "unique_provinces = df_target['Provinsi'].unique()\n",
        "unique_crops = df_target['Jenis Tanaman'].unique()\n",
        "\n",
        "index = pd.MultiIndex.from_product([all_dates, unique_provinces, unique_crops],\n",
        "                                   names=['TANGGAL', 'Provinsi', 'Jenis Tanaman'])\n",
        "df_master = pd.DataFrame(index=index).reset_index()\n",
        "\n",
        "# merge dynamic features and forward/backfill per province to fill gaps\n",
        "df_features = pd.merge(df_climate, df_moisture, on=['TANGGAL', 'Provinsi'], how='outer')\n",
        "df_features = df_features.sort_values('TANGGAL')\n",
        "df_features = df_features.groupby('Provinsi').apply(lambda x: x.ffill().bfill()).reset_index(drop=True)\n",
        "\n",
        "df_master = pd.merge(df_master, df_features, on=['TANGGAL', 'Provinsi'], how='left')\n",
        "df_master = pd.merge(df_master, df_soil_static, on=['Provinsi'], how='left')\n",
        "df_master = pd.merge(df_master, df_harvest, on=['Jenis Tanaman'], how='left')\n",
        "df_master = pd.merge(df_master, df_target, on=['TANGGAL', 'Provinsi', 'Jenis Tanaman'], how='left')\n",
        "\n",
        "# fill static cols\n",
        "static_cols = ['pH', 'Clay_%', 'Sand_%', 'Organic_Carbon_g/kg', 'Avg_Harvest_Days']\n",
        "for col in static_cols:\n",
        "    if col in df_master.columns:\n",
        "        df_master[col] = df_master[col].fillna(df_master[col].mean())\n",
        "\n",
        "df_master = df_master.sort_values(['Provinsi', 'Jenis Tanaman', 'TANGGAL'])\n",
        "\n",
        "# ==========================================\n",
        "# 4. PREPROCESSING\n",
        "# ==========================================\n",
        "print(\"Preprocessing features...\")\n",
        "\n",
        "dynamic_features = ['TN', 'TX', 'TAVG', 'RH_AVG', 'RR', 'SS', 'Soil_Moisture']\n",
        "static_numeric_features = ['pH', 'Clay_%', 'Sand_%', 'Organic_Carbon_g/kg', 'Avg_Harvest_Days']\n",
        "targets = ['Luas Panen', 'Produksi']\n",
        "\n",
        "# Fill zeros\n",
        "for col in dynamic_features:\n",
        "    if col in df_master.columns:\n",
        "        df_master[col] = df_master[col].fillna(0)\n",
        "    else:\n",
        "        df_master[col] = 0.0\n",
        "\n",
        "for t in targets:\n",
        "    if t not in df_master.columns:\n",
        "        df_master[t] = 0.0\n",
        "    df_master[t] = df_master[t].fillna(0.0).astype(float)\n",
        "\n",
        "# LOG TRANSFORM\n",
        "print(\"Applying Log1p Transform to Targets...\")\n",
        "df_master['Luas_log'] = np.log1p(df_master['Luas Panen'].astype(float))\n",
        "df_master['Produksi_log'] = np.log1p(df_master['Produksi'].astype(float))\n",
        "\n",
        "# HYPERTUNING: Use StandardScaler for dynamic features to handle weather outliers better than MinMax\n",
        "scaler_dynamic = StandardScaler()\n",
        "scaler_static = MinMaxScaler()\n",
        "\n",
        "df_master[dynamic_features] = scaler_dynamic.fit_transform(df_master[dynamic_features])\n",
        "df_master[static_numeric_features] = scaler_static.fit_transform(df_master[static_numeric_features])\n",
        "\n",
        "# Label Encode\n",
        "le_prov = LabelEncoder()\n",
        "df_master['Prov_ID'] = le_prov.fit_transform(df_master['Provinsi'])\n",
        "le_crop = LabelEncoder()\n",
        "df_master['Crop_ID'] = le_crop.fit_transform(df_master['Jenis Tanaman'])\n",
        "\n",
        "# ==========================================\n",
        "# 5. CREATE SEQUENCES\n",
        "# ==========================================\n",
        "print(\"Generating sequences...\")\n",
        "\n",
        "train_mask = (df_master['TANGGAL'] >= TRAIN_START) & (df_master['TANGGAL'] <= TRAIN_END)\n",
        "predict_mask = (df_master['TANGGAL'] >= PREDICT_START) & (df_master['TANGGAL'] <= PREDICT_END)\n",
        "\n",
        "df_train_raw = df_master[train_mask].copy()\n",
        "df_predict_raw = df_master[predict_mask].copy()\n",
        "\n",
        "# Fit target scaler (StandardScaler on Log Targets) on TRAIN ONLY\n",
        "log_targets_train = df_train_raw[['Luas_log', 'Produksi_log']].values\n",
        "scaler_target = StandardScaler()\n",
        "scaler_target.fit(log_targets_train)\n",
        "\n",
        "def create_sequences(df, is_training=True):\n",
        "    X_dynamic, X_static, X_prov, X_crop, y, meta = [], [], [], [], [], []\n",
        "    grouped = df.groupby(['Provinsi', 'Jenis Tanaman'])\n",
        "\n",
        "    for (prov, crop), group in grouped:\n",
        "        group = group.sort_values('TANGGAL')\n",
        "        if len(group) <= LOOKBACK_WINDOW:\n",
        "            continue\n",
        "\n",
        "        dyn_data = group[dynamic_features].values\n",
        "        stat_data = group[static_numeric_features].values\n",
        "        prov_id = int(group['Prov_ID'].values[0])\n",
        "        crop_id = int(group['Crop_ID'].values[0])\n",
        "        dates = group['TANGGAL'].values\n",
        "\n",
        "        if is_training:\n",
        "            target_log = group[['Luas_log', 'Produksi_log']].values\n",
        "            target_scaled = scaler_target.transform(target_log)\n",
        "\n",
        "        for i in range(LOOKBACK_WINDOW, len(group)):\n",
        "            X_dynamic.append(dyn_data[i-LOOKBACK_WINDOW:i])\n",
        "            X_static.append(stat_data[i])\n",
        "            X_prov.append(prov_id)\n",
        "            X_crop.append(crop_id)\n",
        "            meta.append([dates[i], prov, crop])\n",
        "            if is_training:\n",
        "                y.append(target_scaled[i])\n",
        "\n",
        "    if len(X_dynamic) == 0:\n",
        "        return (np.empty((0, LOOKBACK_WINDOW, len(dynamic_features))), np.empty((0, len(static_numeric_features))), np.empty((0, 1)), np.empty((0, 1)), np.empty((0, 2)), meta)\n",
        "\n",
        "    X_dyn = np.array(X_dynamic, dtype=np.float32)\n",
        "    X_stat = np.array(X_static, dtype=np.float32)\n",
        "    X_prov = np.array(X_prov, dtype=np.int32).reshape(-1, 1)\n",
        "    X_crop = np.array(X_crop, dtype=np.int32).reshape(-1, 1)\n",
        "    y_arr = np.array(y, dtype=np.float32) if is_training else None\n",
        "\n",
        "    return X_dyn, X_stat, X_prov, X_crop, y_arr, meta\n",
        "\n",
        "X_dyn_train, X_stat_train, X_prov_train, X_crop_train, y_train, _ = create_sequences(df_train_raw, is_training=True)\n",
        "\n",
        "# Prediction buffer\n",
        "last_days_per_group = df_train_raw.groupby(['Provinsi', 'Jenis Tanaman']).tail(LOOKBACK_WINDOW)\n",
        "df_predict_buffered = pd.concat([last_days_per_group, df_predict_raw]).sort_values(['Provinsi', 'Jenis Tanaman', 'TANGGAL'])\n",
        "X_dyn_pred, X_stat_pred, X_prov_pred, X_crop_pred, _, meta_pred = create_sequences(df_predict_buffered, is_training=False)\n",
        "\n",
        "print(\"Training Sequences:\", X_dyn_train.shape)\n",
        "\n",
        "# ==========================================\n",
        "# 6. MODEL ARCHITECTURE (SOTA UPGRADE)\n",
        "# ==========================================\n",
        "def attention_block(inputs):\n",
        "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
        "    input_dim = int(inputs.shape[2])\n",
        "    a = Permute((2, 1))(inputs)\n",
        "    a = Dense(inputs.shape[1], activation='softmax')(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "    output_attention_mul = Multiply()([inputs, a_probs])\n",
        "    return output_attention_mul\n",
        "\n",
        "def build_sota_model(num_provs, num_crops):\n",
        "    # --- Branch 1: Dynamic (Bi-LSTM + Attention) ---\n",
        "    input_dyn = Input(shape=(LOOKBACK_WINDOW, len(dynamic_features)), name='dynamic_input')\n",
        "\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(input_dyn)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('swish')(x) # Swish is often better than ReLU for deep regressors\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Self-Attention Mechanism to weigh important days\n",
        "    x = attention_block(x)\n",
        "    x = GlobalAveragePooling1D()(x) # Collapse time dimension weighted by attention\n",
        "\n",
        "    # --- Branch 2: Static ---\n",
        "    input_stat = Input(shape=(len(static_numeric_features),), name='static_input')\n",
        "    x_stat = Dense(64)(input_stat)\n",
        "    x_stat = BatchNormalization()(x_stat)\n",
        "    x_stat = Activation('swish')(x_stat)\n",
        "\n",
        "    # --- Branch 3: Embeddings (Increased Capacity) ---\n",
        "    # Larger dim helps memorize high-production provinces\n",
        "    input_prov = Input(shape=(1,), name='prov_input')\n",
        "    emb_prov = Embedding(input_dim=num_provs, output_dim=24)(input_prov)\n",
        "    emb_prov = Flatten()(emb_prov)\n",
        "\n",
        "    input_crop = Input(shape=(1,), name='crop_input')\n",
        "    emb_crop = Embedding(input_dim=num_crops, output_dim=16)(input_crop)\n",
        "    emb_crop = Flatten()(emb_crop)\n",
        "\n",
        "    # --- Fusion ---\n",
        "    combined = Concatenate()([x, x_stat, emb_prov, emb_crop])\n",
        "\n",
        "    # --- Deep Interaction Block ---\n",
        "    z = Dense(256)(combined)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation('swish')(z)\n",
        "    z = Dropout(0.3)(z)\n",
        "\n",
        "    z = Dense(128)(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation('swish')(z)\n",
        "\n",
        "    # --- SEPARATE TOWERS (Multi-Task Learning) ---\n",
        "    # Tower 1: Luas Panen\n",
        "    t1 = Dense(64, activation='swish')(z)\n",
        "    t1 = Dense(32, activation='swish')(t1)\n",
        "    out1 = Dense(1, name='out_luas')(t1)\n",
        "\n",
        "    # Tower 2: Produksi\n",
        "    t2 = Dense(64, activation='swish')(z)\n",
        "    t2 = Dense(32, activation='swish')(t2)\n",
        "    out2 = Dense(1, name='out_prod')(t2)\n",
        "\n",
        "    # Recombine for simple compatibility with array target\n",
        "    output = Concatenate(name='final_output')([out1, out2])\n",
        "\n",
        "    model = Model(inputs=[input_dyn, input_stat, input_prov, input_crop], outputs=output)\n",
        "\n",
        "    # Nadam is Adam with Nesterov momentum, often converges faster/better\n",
        "    model.compile(optimizer=Nadam(learning_rate=2e-3), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model = build_sota_model(num_provs=len(unique_provinces), num_crops=len(unique_crops))\n",
        "model.summary()\n",
        "\n",
        "# ==========================================\n",
        "# 7. TRAINING\n",
        "# ==========================================\n",
        "print(\"Training model...\")\n",
        "\n",
        "if X_dyn_train.shape[0] == 0:\n",
        "    raise RuntimeError(\"No training data.\")\n",
        "\n",
        "X_dyn_tr, X_dyn_val, X_stat_tr, X_stat_val, X_p_tr, X_p_val, X_c_tr, X_c_val, y_tr, y_val = train_test_split(\n",
        "    X_dyn_train, X_stat_train, X_prov_train, X_crop_train, y_train, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    x=[X_dyn_tr, X_stat_tr, X_p_tr, X_c_tr],\n",
        "    y=y_tr,\n",
        "    validation_data=([X_dyn_val, X_stat_val, X_p_val, X_c_val], y_val),\n",
        "    epochs=80, # More epochs, relying on early stopping\n",
        "    batch_size=128,\n",
        "    callbacks=[early_stop, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 7.5 EVALUATION\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"EVALUATION ON VALIDATION SET\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "y_pred_scaled = model.predict([X_dyn_val, X_stat_val, X_p_val, X_c_val], batch_size=512)\n",
        "\n",
        "# Inverse transform\n",
        "y_val_log = scaler_target.inverse_transform(y_val)\n",
        "y_pred_log = scaler_target.inverse_transform(y_pred_scaled)\n",
        "\n",
        "y_val_real = np.expm1(y_val_log)\n",
        "y_pred_real = np.expm1(y_pred_log)\n",
        "y_pred_real = np.clip(y_pred_real, 0, None)\n",
        "\n",
        "def masked_mape(a, f, min_denominator=1.0):\n",
        "    denom = np.maximum(np.abs(a), min_denominator)\n",
        "    return 100.0 * np.mean(np.abs((a - f) / denom))\n",
        "\n",
        "targets_list = ['Luas Panen', 'Produksi']\n",
        "for i, target_name in enumerate(targets_list):\n",
        "    actual = y_val_real[:, i]\n",
        "    predicted = y_pred_real[:, i]\n",
        "\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    r2 = r2_score(actual, predicted)\n",
        "    mape_masked = masked_mape(actual, predicted, min_denominator=1.0)\n",
        "\n",
        "    print(f\"\\nResults for {target_name}:\")\n",
        "    print(f\"  MAE    : {mae:,.2f}\")\n",
        "    print(f\"  RMSE   : {rmse:,.2f}\")\n",
        "    print(f\"  MAPE* : {mape_masked:.2f}%\")\n",
        "    print(f\"  R2     : {r2:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(actual, predicted, alpha=0.4, s=15, edgecolors='k', linewidth=0.1)\n",
        "    min_val = float(min(actual.min(), predicted.min()))\n",
        "    max_val = float(max(actual.max(), predicted.max()))\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "    plt.xlabel(f'Actual {target_name}')\n",
        "    plt.ylabel(f'Predicted {target_name}')\n",
        "    plt.title(f'{target_name}: Actual vs Predicted\\nR2: {r2:.3f}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    save_path = PATHS['plot_luas'] if i == 0 else PATHS['plot_prod']\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "# ==========================================\n",
        "# 8. FINAL PREDICTION\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"GENERATING FUTURE PREDICTIONS (2025)\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "if X_dyn_pred.shape[0] > 0:\n",
        "    preds_scaled = model.predict([X_dyn_pred, X_stat_pred, X_prov_pred, X_crop_pred], batch_size=512)\n",
        "    preds_log = scaler_target.inverse_transform(preds_scaled)\n",
        "    preds_original = np.expm1(preds_log)\n",
        "    preds_original = np.clip(preds_original, 0, None)\n",
        "\n",
        "    df_result = pd.DataFrame(meta_pred, columns=['Date', 'Provinsi', 'Jenis Tanaman'])\n",
        "    df_result['Luas Panen'] = preds_original[:, 0]\n",
        "    df_result['Produksi'] = preds_original[:, 1]\n",
        "    df_result['Date'] = pd.to_datetime(df_result['Date'])\n",
        "    df_result = df_result.sort_values(['Date', 'Provinsi', 'Jenis Tanaman'])\n",
        "\n",
        "    print(f\"Saving to {PATHS['output']}...\")\n",
        "    df_result.to_csv(PATHS['output'], index=False)\n",
        "    print(\"✅ Saved predictions.\")\n",
        "else:\n",
        "    print(\"No prediction data available.\")\n",
        "\n",
        "print(\"✅ Process complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hs-DBbyYA_G7",
        "outputId": "4715f1f5-b54b-4eca-ac4b-d5065117c44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found wow.zip. Extracting...\n",
            "✅ Extraction complete.\n",
            "Num GPUs Available:  1\n",
            "Loading datasets...\n",
            "Merging data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4130838162.py:112: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_features = df_features.groupby('Provinsi').apply(lambda x: x.ffill().bfill()).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing features...\n",
            "Applying Log1p Transform to Targets...\n",
            "Generating sequences...\n",
            "Training Sequences: (192090, 90, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ dynamic_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m7\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m139,264\u001b[0m │ dynamic_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m90\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m90\u001b[0m)   │      \u001b[38;5;34m8,190\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ static_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_vec       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mPermute\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m384\u001b[0m │ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prov_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ crop_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ attention_vec[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m24\u001b[0m)     │        \u001b[38;5;34m912\u001b[0m │ prov_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m240\u001b[0m │ crop_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m92,416\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_luas (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_prod (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ out_luas[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ out_prod[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ dynamic_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">139,264</span> │ dynamic_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,190</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ static_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_vec       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prov_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ crop_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ attention_vec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">912</span> │ prov_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ crop_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">92,416</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_luas (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_prod (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ out_luas[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ out_prod[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m297,856\u001b[0m (1.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">297,856</span> (1.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m296,448\u001b[0m (1.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> (1.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 32ms/step - loss: 0.1625 - mae: 0.2854 - val_loss: 0.0295 - val_mae: 0.1284 - learning_rate: 0.0020\n",
            "Epoch 2/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0386 - mae: 0.1485 - val_loss: 0.0267 - val_mae: 0.1233 - learning_rate: 0.0020\n",
            "Epoch 3/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - loss: 0.0321 - mae: 0.1354 - val_loss: 0.0251 - val_mae: 0.1186 - learning_rate: 0.0020\n",
            "Epoch 4/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0298 - mae: 0.1302 - val_loss: 0.0249 - val_mae: 0.1177 - learning_rate: 0.0020\n",
            "Epoch 5/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0285 - mae: 0.1270 - val_loss: 0.0252 - val_mae: 0.1184 - learning_rate: 0.0020\n",
            "Epoch 6/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0274 - mae: 0.1247 - val_loss: 0.0250 - val_mae: 0.1197 - learning_rate: 0.0020\n",
            "Epoch 7/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0269 - mae: 0.1230 - val_loss: 0.0241 - val_mae: 0.1174 - learning_rate: 0.0020\n",
            "Epoch 8/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0264 - mae: 0.1219 - val_loss: 0.0245 - val_mae: 0.1171 - learning_rate: 0.0020\n",
            "Epoch 9/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0261 - mae: 0.1215 - val_loss: 0.0236 - val_mae: 0.1140 - learning_rate: 0.0020\n",
            "Epoch 10/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0258 - mae: 0.1204 - val_loss: 0.0236 - val_mae: 0.1123 - learning_rate: 0.0020\n",
            "Epoch 11/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0254 - mae: 0.1193 - val_loss: 0.0231 - val_mae: 0.1125 - learning_rate: 0.0020\n",
            "Epoch 12/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0252 - mae: 0.1187 - val_loss: 0.0234 - val_mae: 0.1158 - learning_rate: 0.0020\n",
            "Epoch 13/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0250 - mae: 0.1184 - val_loss: 0.0237 - val_mae: 0.1137 - learning_rate: 0.0020\n",
            "Epoch 14/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0250 - mae: 0.1182 - val_loss: 0.0239 - val_mae: 0.1149 - learning_rate: 0.0020\n",
            "Epoch 15/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0248 - mae: 0.1176\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0248 - mae: 0.1176 - val_loss: 0.0234 - val_mae: 0.1147 - learning_rate: 0.0020\n",
            "Epoch 16/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0239 - mae: 0.1154 - val_loss: 0.0229 - val_mae: 0.1122 - learning_rate: 0.0010\n",
            "Epoch 17/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0237 - mae: 0.1148 - val_loss: 0.0233 - val_mae: 0.1126 - learning_rate: 0.0010\n",
            "Epoch 18/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0239 - mae: 0.1154 - val_loss: 0.0226 - val_mae: 0.1105 - learning_rate: 0.0010\n",
            "Epoch 19/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0238 - mae: 0.1151 - val_loss: 0.0227 - val_mae: 0.1114 - learning_rate: 0.0010\n",
            "Epoch 20/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0235 - mae: 0.1144 - val_loss: 0.0227 - val_mae: 0.1100 - learning_rate: 0.0010\n",
            "Epoch 21/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0237 - mae: 0.1148 - val_loss: 0.0227 - val_mae: 0.1108 - learning_rate: 0.0010\n",
            "Epoch 22/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0233 - mae: 0.1136\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0233 - mae: 0.1136 - val_loss: 0.0231 - val_mae: 0.1117 - learning_rate: 0.0010\n",
            "Epoch 23/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0233 - mae: 0.1137 - val_loss: 0.0226 - val_mae: 0.1108 - learning_rate: 5.0000e-04\n",
            "Epoch 24/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0231 - mae: 0.1129 - val_loss: 0.0225 - val_mae: 0.1128 - learning_rate: 5.0000e-04\n",
            "Epoch 25/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0231 - mae: 0.1133 - val_loss: 0.0223 - val_mae: 0.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 26/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0231 - mae: 0.1132 - val_loss: 0.0224 - val_mae: 0.1101 - learning_rate: 5.0000e-04\n",
            "Epoch 27/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0231 - mae: 0.1131 - val_loss: 0.0225 - val_mae: 0.1123 - learning_rate: 5.0000e-04\n",
            "Epoch 28/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0230 - mae: 0.1130 - val_loss: 0.0225 - val_mae: 0.1088 - learning_rate: 5.0000e-04\n",
            "Epoch 29/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0230 - mae: 0.1128\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0230 - mae: 0.1128 - val_loss: 0.0224 - val_mae: 0.1119 - learning_rate: 5.0000e-04\n",
            "Epoch 30/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0229 - mae: 0.1126 - val_loss: 0.0223 - val_mae: 0.1111 - learning_rate: 2.5000e-04\n",
            "Epoch 31/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0229 - mae: 0.1125 - val_loss: 0.0224 - val_mae: 0.1103 - learning_rate: 2.5000e-04\n",
            "Epoch 32/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0227 - mae: 0.1120 - val_loss: 0.0223 - val_mae: 0.1102 - learning_rate: 2.5000e-04\n",
            "Epoch 33/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0228 - mae: 0.1121 - val_loss: 0.0222 - val_mae: 0.1105 - learning_rate: 2.5000e-04\n",
            "Epoch 34/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0227 - mae: 0.1121 - val_loss: 0.0223 - val_mae: 0.1087 - learning_rate: 2.5000e-04\n",
            "Epoch 35/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0227 - mae: 0.1118 - val_loss: 0.0223 - val_mae: 0.1094 - learning_rate: 2.5000e-04\n",
            "Epoch 36/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0228 - mae: 0.1123 - val_loss: 0.0223 - val_mae: 0.1112 - learning_rate: 2.5000e-04\n",
            "Epoch 37/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0227 - mae: 0.1118\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0227 - mae: 0.1118 - val_loss: 0.0223 - val_mae: 0.1093 - learning_rate: 2.5000e-04\n",
            "Epoch 38/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0227 - mae: 0.1120 - val_loss: 0.0222 - val_mae: 0.1090 - learning_rate: 1.2500e-04\n",
            "Epoch 39/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0226 - mae: 0.1116 - val_loss: 0.0222 - val_mae: 0.1095 - learning_rate: 1.2500e-04\n",
            "Epoch 40/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0221 - val_mae: 0.1103 - learning_rate: 1.2500e-04\n",
            "Epoch 41/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0225 - mae: 0.1114\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0222 - val_mae: 0.1092 - learning_rate: 1.2500e-04\n",
            "Epoch 42/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0226 - mae: 0.1117 - val_loss: 0.0222 - val_mae: 0.1093 - learning_rate: 6.2500e-05\n",
            "Epoch 43/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1112 - val_loss: 0.0221 - val_mae: 0.1091 - learning_rate: 6.2500e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1115 - val_loss: 0.0221 - val_mae: 0.1091 - learning_rate: 6.2500e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0222 - val_mae: 0.1094 - learning_rate: 6.2500e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0221 - val_mae: 0.1095 - learning_rate: 6.2500e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0223 - mae: 0.1109\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0223 - mae: 0.1109 - val_loss: 0.0221 - val_mae: 0.1096 - learning_rate: 6.2500e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0224 - mae: 0.1110 - val_loss: 0.0221 - val_mae: 0.1093 - learning_rate: 3.1250e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0226 - mae: 0.1117 - val_loss: 0.0221 - val_mae: 0.1093 - learning_rate: 3.1250e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1113 - val_loss: 0.0221 - val_mae: 0.1093 - learning_rate: 3.1250e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0225 - mae: 0.1114\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0221 - val_mae: 0.1093 - learning_rate: 3.1250e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1115 - val_loss: 0.0221 - val_mae: 0.1089 - learning_rate: 1.5625e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0226 - mae: 0.1115 - val_loss: 0.0221 - val_mae: 0.1094 - learning_rate: 1.5625e-05\n",
            "Epoch 54/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0221 - val_mae: 0.1091 - learning_rate: 1.5625e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m1275/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0225 - mae: 0.1114\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - loss: 0.0225 - mae: 0.1114 - val_loss: 0.0221 - val_mae: 0.1094 - learning_rate: 1.5625e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0224 - mae: 0.1109 - val_loss: 0.0221 - val_mae: 0.1094 - learning_rate: 7.8125e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0223 - mae: 0.1108 - val_loss: 0.0221 - val_mae: 0.1090 - learning_rate: 7.8125e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m1276/1276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0224 - mae: 0.1110 - val_loss: 0.0221 - val_mae: 0.1096 - learning_rate: 7.8125e-06\n",
            "Epoch 58: early stopping\n",
            "Restoring model weights from the end of the best epoch: 46.\n",
            "\n",
            "========================================\n",
            "EVALUATION ON VALIDATION SET\n",
            "========================================\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n",
            "\n",
            "Results for Luas Panen:\n",
            "  MAE    : 517.45\n",
            "  RMSE   : 3,352.86\n",
            "  MAPE* : 41.82%\n",
            "  R2     : 0.8273\n",
            "\n",
            "Results for Produksi:\n",
            "  MAE    : 1,427.17\n",
            "  RMSE   : 7,870.98\n",
            "  MAPE* : 44.92%\n",
            "  R2     : 0.8202\n",
            "\n",
            "========================================\n",
            "GENERATING FUTURE PREDICTIONS (2025)\n",
            "========================================\n",
            "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "Saving to ./Biofarmaka_Prediction_2025.csv...\n",
            "✅ Saved predictions.\n",
            "✅ Process complete.\n"
          ]
        }
      ]
    }
  ]
}